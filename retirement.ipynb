{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('dataset/best places for retirement in usa.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+--------------+-----+-------+-------------------+-----+-------+----------+\n",
      "|         STATE|OVERALL RANK|COST OF LIVING|CRIME|CULTURE|HEALTH CARE QUALITY|TAXES|WEATHER|WELL-BEING|\n",
      "+--------------+------------+--------------+-----+-------+-------------------+-----+-------+----------+\n",
      "|  South Dakota|           1|            19|   21|     10|                 12|    2|     38|         1|\n",
      "|          Utah|           2|            25|   22|     15|                 10|    8|     32|         9|\n",
      "|         Idaho|           3|            12|    4|     31|                  8|   20|     41|         8|\n",
      "| New Hampshire|           4|            43|    1|      9|                  5|    7|     43|         7|\n",
      "|       Florida|           5|            27|   33|     26|                 36|    4|      2|        12|\n",
      "|       Montana|           6|            23|   26|      7|                 19|    6|     45|        10|\n",
      "|North Carolina|           6|            12|   29|     40|                 30|   11|     12|        19|\n",
      "|       Wyoming|           8|            28|    9|     16|                 22|    1|     46|        16|\n",
      "|      Nebraska|           9|            17|   18|     25|                 12|   25|     29|        17|\n",
      "|   Mississippi|          10|             1|   23|     48|                 26|   24|      5|        47|\n",
      "|        Hawaii|          11|            48|   35|      3|                 17|   27|      1|         3|\n",
      "| Massachusetts|          12|            46|   14|      2|                  3|   22|     34|        11|\n",
      "|      Virginia|          13|            30|    4|     17|                 24|   31|     16|        18|\n",
      "|      Michigan|          14|             4|   23|     27|                 32|   12|     40|        32|\n",
      "|      Missouri|          15|             3|   41|     28|                 35|   16|     17|        39|\n",
      "|          Iowa|          16|            11|   16|     18|                 12|   40|     33|        21|\n",
      "|      Colorado|          17|            35|   28|     12|                 15|   18|     37|         6|\n",
      "|         Texas|          17|            20|   36|     43|                 44|   13|      4|        13|\n",
      "|      Delaware|          19|            32|   40|     24|                  6|   15|     18|        40|\n",
      "|  North Dakota|          20|            29|   17|     14|                  8|   30|     49|         5|\n",
      "+--------------+------------+--------------+-----+-------+-------------------+-----+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total data points: 50\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "print(\"Total data points:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv('dataset/state abbreviation.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------+------------+\n",
      "|      State|    Standard|Postal|Capital City|\n",
      "+-----------+------------+------+------------+\n",
      "|       null|Abbreviation|  null|        null|\n",
      "|    Alabama|        Ala.|    AL|  Montgomery|\n",
      "|     Alaska|      Alaska|    AK|      Juneau|\n",
      "|    Arizona|       Ariz.|    AZ|     Phoenix|\n",
      "|   Arkansas|        Ark.|    AR| Little Rock|\n",
      "| California|      Calif.|    CA|  Sacramento|\n",
      "|   Colorado|       Colo.|    CO|      Denver|\n",
      "|Connecticut|       Conn.|    CT|    Hartford|\n",
      "|   Delaware|        Del.|    DE|       Dover|\n",
      "|    Florida|        Fla.|    FL| Tallahassee|\n",
      "|    Georgia|         Ga.|    GA|     Atlanta|\n",
      "|     Hawaii|      Hawaii|    HI|    Honolulu|\n",
      "|      Idaho|       Idaho|    ID|       Boise|\n",
      "|   Illinois|        Ill.|    IL| Springfield|\n",
      "|    Indiana|        Ind.|    IN|Indianapolis|\n",
      "|       Iowa|        Iowa|    IA|  Des Moines|\n",
      "|     Kansas|       Kans.|    KS|      Topeka|\n",
      "|   Kentucky|         Ky.|    KY|   Frankfort|\n",
      "|  Louisiana|         La.|    LA| Baton Rouge|\n",
      "|      Maine|       Maine|    ME|     Augusta|\n",
      "+-----------+------------+------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total data points: 50\n"
     ]
    }
   ],
   "source": [
    "df1.show()\n",
    "print(\"Total data points:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------+\n",
      "|      State|    Standard|Capital City|\n",
      "+-----------+------------+------------+\n",
      "|       null|Abbreviation|        null|\n",
      "|    Alabama|        Ala.|  Montgomery|\n",
      "|     Alaska|      Alaska|      Juneau|\n",
      "|    Arizona|       Ariz.|     Phoenix|\n",
      "|   Arkansas|        Ark.| Little Rock|\n",
      "| California|      Calif.|  Sacramento|\n",
      "|   Colorado|       Colo.|      Denver|\n",
      "|Connecticut|       Conn.|    Hartford|\n",
      "|   Delaware|        Del.|       Dover|\n",
      "|    Florida|        Fla.| Tallahassee|\n",
      "|    Georgia|         Ga.|     Atlanta|\n",
      "|     Hawaii|      Hawaii|    Honolulu|\n",
      "|      Idaho|       Idaho|       Boise|\n",
      "|   Illinois|        Ill.| Springfield|\n",
      "|    Indiana|        Ind.|Indianapolis|\n",
      "|       Iowa|        Iowa|  Des Moines|\n",
      "|     Kansas|       Kans.|      Topeka|\n",
      "|   Kentucky|         Ky.|   Frankfort|\n",
      "|  Louisiana|         La.| Baton Rouge|\n",
      "|      Maine|       Maine|     Augusta|\n",
      "+-----------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.drop(df1.Postal).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|      State|    Standard|\n",
      "+-----------+------------+\n",
      "|       null|Abbreviation|\n",
      "|    Alabama|        Ala.|\n",
      "|     Alaska|      Alaska|\n",
      "|    Arizona|       Ariz.|\n",
      "|   Arkansas|        Ark.|\n",
      "| California|      Calif.|\n",
      "|   Colorado|       Colo.|\n",
      "|Connecticut|       Conn.|\n",
      "|   Delaware|        Del.|\n",
      "|    Florida|        Fla.|\n",
      "|    Georgia|         Ga.|\n",
      "|     Hawaii|      Hawaii|\n",
      "|      Idaho|       Idaho|\n",
      "|   Illinois|        Ill.|\n",
      "|    Indiana|        Ind.|\n",
      "|       Iowa|        Iowa|\n",
      "|     Kansas|       Kans.|\n",
      "|   Kentucky|         Ky.|\n",
      "|  Louisiana|         La.|\n",
      "|      Maine|       Maine|\n",
      "+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.drop('Capital City','Postal').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|      STATE|Abbreviation|\n",
      "+-----------+------------+\n",
      "|       null|Abbreviation|\n",
      "|    Alabama|        Ala.|\n",
      "|     Alaska|      Alaska|\n",
      "|    Arizona|       Ariz.|\n",
      "|   Arkansas|        Ark.|\n",
      "| California|      Calif.|\n",
      "|   Colorado|       Colo.|\n",
      "|Connecticut|       Conn.|\n",
      "|   Delaware|        Del.|\n",
      "|    Florida|        Fla.|\n",
      "|    Georgia|         Ga.|\n",
      "|     Hawaii|      Hawaii|\n",
      "|      Idaho|       Idaho|\n",
      "|   Illinois|        Ill.|\n",
      "|    Indiana|        Ind.|\n",
      "|       Iowa|        Iowa|\n",
      "|     Kansas|       Kans.|\n",
      "|   Kentucky|         Ky.|\n",
      "|  Louisiana|         La.|\n",
      "|      Maine|       Maine|\n",
      "+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.selectExpr(\"State as STATE\",\"Standard as Abbreviation\") .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.selectExpr(\"State as STATE\",\"Standard as Abbreviation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|      STATE|Abbreviation|\n",
      "+-----------+------------+\n",
      "|       null|Abbreviation|\n",
      "|    Alabama|        Ala.|\n",
      "|     Alaska|      Alaska|\n",
      "|    Arizona|       Ariz.|\n",
      "|   Arkansas|        Ark.|\n",
      "| California|      Calif.|\n",
      "|   Colorado|       Colo.|\n",
      "|Connecticut|       Conn.|\n",
      "|   Delaware|        Del.|\n",
      "|    Florida|        Fla.|\n",
      "|    Georgia|         Ga.|\n",
      "|     Hawaii|      Hawaii|\n",
      "|      Idaho|       Idaho|\n",
      "|   Illinois|        Ill.|\n",
      "|    Indiana|        Ind.|\n",
      "|       Iowa|        Iowa|\n",
      "|     Kansas|       Kans.|\n",
      "|   Kentucky|         Ky.|\n",
      "|  Louisiana|         La.|\n",
      "|      Maine|       Maine|\n",
      "+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|      STATE|Abbreviation|\n",
      "+-----------+------------+\n",
      "|    Alabama|        Ala.|\n",
      "|     Alaska|      Alaska|\n",
      "|    Arizona|       Ariz.|\n",
      "|   Arkansas|        Ark.|\n",
      "| California|      Calif.|\n",
      "|   Colorado|       Colo.|\n",
      "|Connecticut|       Conn.|\n",
      "|   Delaware|        Del.|\n",
      "|    Florida|        Fla.|\n",
      "|    Georgia|         Ga.|\n",
      "|     Hawaii|      Hawaii|\n",
      "|      Idaho|       Idaho|\n",
      "|   Illinois|        Ill.|\n",
      "|    Indiana|        Ind.|\n",
      "|       Iowa|        Iowa|\n",
      "|     Kansas|       Kans.|\n",
      "|   Kentucky|         Ky.|\n",
      "|  Louisiana|         La.|\n",
      "|      Maine|       Maine|\n",
      "|   Maryland|         Md.|\n",
      "+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+--------------+-----+-------+-------------------+-----+-------+----------+\n",
      "|         STATE|OVERALL RANK|COST OF LIVING|CRIME|CULTURE|HEALTH CARE QUALITY|TAXES|WEATHER|WELL-BEING|\n",
      "+--------------+------------+--------------+-----+-------+-------------------+-----+-------+----------+\n",
      "|  South Dakota|           1|            19|   21|     10|                 12|    2|     38|         1|\n",
      "|          Utah|           2|            25|   22|     15|                 10|    8|     32|         9|\n",
      "|         Idaho|           3|            12|    4|     31|                  8|   20|     41|         8|\n",
      "| New Hampshire|           4|            43|    1|      9|                  5|    7|     43|         7|\n",
      "|       Florida|           5|            27|   33|     26|                 36|    4|      2|        12|\n",
      "|       Montana|           6|            23|   26|      7|                 19|    6|     45|        10|\n",
      "|North Carolina|           6|            12|   29|     40|                 30|   11|     12|        19|\n",
      "|       Wyoming|           8|            28|    9|     16|                 22|    1|     46|        16|\n",
      "|      Nebraska|           9|            17|   18|     25|                 12|   25|     29|        17|\n",
      "|   Mississippi|          10|             1|   23|     48|                 26|   24|      5|        47|\n",
      "|        Hawaii|          11|            48|   35|      3|                 17|   27|      1|         3|\n",
      "| Massachusetts|          12|            46|   14|      2|                  3|   22|     34|        11|\n",
      "|      Virginia|          13|            30|    4|     17|                 24|   31|     16|        18|\n",
      "|      Michigan|          14|             4|   23|     27|                 32|   12|     40|        32|\n",
      "|      Missouri|          15|             3|   41|     28|                 35|   16|     17|        39|\n",
      "|          Iowa|          16|            11|   16|     18|                 12|   40|     33|        21|\n",
      "|      Colorado|          17|            35|   28|     12|                 15|   18|     37|         6|\n",
      "|         Texas|          17|            20|   36|     43|                 44|   13|      4|        13|\n",
      "|      Delaware|          19|            32|   40|     24|                  6|   15|     18|        40|\n",
      "|  North Dakota|          20|            29|   17|     14|                  8|   30|     49|         5|\n",
      "+--------------+------------+--------------+-----+-------+-------------------+-----+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|      STATE|Abbreviation|\n",
      "+-----------+------------+\n",
      "|    Alabama|        Ala.|\n",
      "|     Alaska|      Alaska|\n",
      "|    Arizona|       Ariz.|\n",
      "|   Arkansas|        Ark.|\n",
      "| California|      Calif.|\n",
      "|   Colorado|       Colo.|\n",
      "|Connecticut|       Conn.|\n",
      "|   Delaware|        Del.|\n",
      "|    Florida|        Fla.|\n",
      "|    Georgia|         Ga.|\n",
      "|     Hawaii|      Hawaii|\n",
      "|      Idaho|       Idaho|\n",
      "|   Illinois|        Ill.|\n",
      "|    Indiana|        Ind.|\n",
      "|       Iowa|        Iowa|\n",
      "|     Kansas|       Kans.|\n",
      "|   Kentucky|         Ky.|\n",
      "|  Louisiana|         La.|\n",
      "|      Maine|       Maine|\n",
      "|   Maryland|         Md.|\n",
      "+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df.join(df3, df.STATE == df3.STATE, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+--------------+-----+-------+-------------------+-----+-------+----------+--------------+------------+\n",
      "|         STATE|OVERALL RANK|COST OF LIVING|CRIME|CULTURE|HEALTH CARE QUALITY|TAXES|WEATHER|WELL-BEING|         STATE|Abbreviation|\n",
      "+--------------+------------+--------------+-----+-------+-------------------+-----+-------+----------+--------------+------------+\n",
      "|  South Dakota|           1|            19|   21|     10|                 12|    2|     38|         1|  South Dakota|        S.D.|\n",
      "|          Utah|           2|            25|   22|     15|                 10|    8|     32|         9|          Utah|        Utah|\n",
      "|         Idaho|           3|            12|    4|     31|                  8|   20|     41|         8|         Idaho|       Idaho|\n",
      "| New Hampshire|           4|            43|    1|      9|                  5|    7|     43|         7| New Hampshire|        N.H.|\n",
      "|       Florida|           5|            27|   33|     26|                 36|    4|      2|        12|       Florida|        Fla.|\n",
      "|       Montana|           6|            23|   26|      7|                 19|    6|     45|        10|       Montana|       Mont.|\n",
      "|North Carolina|           6|            12|   29|     40|                 30|   11|     12|        19|North Carolina|        N.C.|\n",
      "|       Wyoming|           8|            28|    9|     16|                 22|    1|     46|        16|       Wyoming|        Wyo.|\n",
      "|      Nebraska|           9|            17|   18|     25|                 12|   25|     29|        17|      Nebraska|       Nebr.|\n",
      "|   Mississippi|          10|             1|   23|     48|                 26|   24|      5|        47|   Mississippi|       Miss.|\n",
      "|        Hawaii|          11|            48|   35|      3|                 17|   27|      1|         3|        Hawaii|      Hawaii|\n",
      "| Massachusetts|          12|            46|   14|      2|                  3|   22|     34|        11| Massachusetts|       Mass.|\n",
      "|      Virginia|          13|            30|    4|     17|                 24|   31|     16|        18|      Virginia|         Va.|\n",
      "|      Michigan|          14|             4|   23|     27|                 32|   12|     40|        32|      Michigan|       Mich.|\n",
      "|      Missouri|          15|             3|   41|     28|                 35|   16|     17|        39|      Missouri|         Mo.|\n",
      "|          Iowa|          16|            11|   16|     18|                 12|   40|     33|        21|          Iowa|        Iowa|\n",
      "|      Colorado|          17|            35|   28|     12|                 15|   18|     37|         6|      Colorado|       Colo.|\n",
      "|         Texas|          17|            20|   36|     43|                 44|   13|      4|        13|         Texas|        Tex.|\n",
      "|      Delaware|          19|            32|   40|     24|                  6|   15|     18|        40|      Delaware|        Del.|\n",
      "|  North Dakota|          20|            29|   17|     14|                  8|   30|     49|         5|  North Dakota|        N.D.|\n",
      "+--------------+------------+--------------+-----+-------+-------------------+-----+-------+----------+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned=df_join.drop('STATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-----+-------+-------------------+-----+-------+----------+------------+\n",
      "|OVERALL RANK|COST OF LIVING|CRIME|CULTURE|HEALTH CARE QUALITY|TAXES|WEATHER|WELL-BEING|Abbreviation|\n",
      "+------------+--------------+-----+-------+-------------------+-----+-------+----------+------------+\n",
      "|           1|            19|   21|     10|                 12|    2|     38|         1|        S.D.|\n",
      "|           2|            25|   22|     15|                 10|    8|     32|         9|        Utah|\n",
      "|           3|            12|    4|     31|                  8|   20|     41|         8|       Idaho|\n",
      "|           4|            43|    1|      9|                  5|    7|     43|         7|        N.H.|\n",
      "|           5|            27|   33|     26|                 36|    4|      2|        12|        Fla.|\n",
      "|           6|            23|   26|      7|                 19|    6|     45|        10|       Mont.|\n",
      "|           6|            12|   29|     40|                 30|   11|     12|        19|        N.C.|\n",
      "|           8|            28|    9|     16|                 22|    1|     46|        16|        Wyo.|\n",
      "|           9|            17|   18|     25|                 12|   25|     29|        17|       Nebr.|\n",
      "|          10|             1|   23|     48|                 26|   24|      5|        47|       Miss.|\n",
      "|          11|            48|   35|      3|                 17|   27|      1|         3|      Hawaii|\n",
      "|          12|            46|   14|      2|                  3|   22|     34|        11|       Mass.|\n",
      "|          13|            30|    4|     17|                 24|   31|     16|        18|         Va.|\n",
      "|          14|             4|   23|     27|                 32|   12|     40|        32|       Mich.|\n",
      "|          15|             3|   41|     28|                 35|   16|     17|        39|         Mo.|\n",
      "|          16|            11|   16|     18|                 12|   40|     33|        21|        Iowa|\n",
      "|          17|            35|   28|     12|                 15|   18|     37|         6|       Colo.|\n",
      "|          17|            20|   36|     43|                 44|   13|      4|        13|        Tex.|\n",
      "|          19|            32|   40|     24|                  6|   15|     18|        40|        Del.|\n",
      "|          20|            29|   17|     14|                  8|   30|     49|         5|        N.D.|\n",
      "+------------+--------------+-----+-------+-------------------+-----+-------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OVERALL RANK: integer (nullable = true)\n",
      " |-- COST OF LIVING: integer (nullable = true)\n",
      " |-- CRIME: integer (nullable = true)\n",
      " |-- CULTURE: integer (nullable = true)\n",
      " |-- HEALTH CARE QUALITY: integer (nullable = true)\n",
      " |-- TAXES: integer (nullable = true)\n",
      " |-- WEATHER: integer (nullable = true)\n",
      " |-- WELL-BEING: integer (nullable = true)\n",
      " |-- Abbreviation: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vector_assembler = VectorAssembler(inputCols = ['COST OF LIVING', 'CRIME', 'CULTURE', 'HEALTH CARE QUALITY', 'TAXES', 'WEATHER', 'WELL-BEING'], outputCol = 'features')\n",
    "vector_output = vector_assembler.transform(df_cleaned)\n",
    "vector_output.printSchema()\n",
    "vector_output.head(1)\n",
    "label_features = vector_output.select(\"features\", \"OVERALL RANK\").toDF('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.5377954783573055,0.31863042823930177,0.27042046264877695,0.39939032585469436,0.5863370813768883,0.41744286277886206,0.30592345607112087]\n",
      "Intercept: -46.66317408656304\n",
      "RMSE: 2.4938659687207387\n",
      "R2: 0.9701680378456282\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lrModel = lr.fit(label_features)\n",
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "df_cleaned_summary =lrModel.summary\n",
    "print(\"RMSE: \" + str(df_cleaned_summary.rootMeanSquaredError))\n",
    "print(\"R2: \" + str(df_cleaned_summary.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = vector_output.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- OVERALL RANK: integer (nullable = true)\n",
      " |-- COST OF LIVING: integer (nullable = true)\n",
      " |-- CRIME: integer (nullable = true)\n",
      " |-- CULTURE: integer (nullable = true)\n",
      " |-- HEALTH CARE QUALITY: integer (nullable = true)\n",
      " |-- TAXES: integer (nullable = true)\n",
      " |-- WEATHER: integer (nullable = true)\n",
      " |-- WELL-BEING: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cache()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iteration=df_cleaned.select('OVERALL RANK', 'COST OF LIVING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+\n",
      "|OVERALL RANK|COST OF LIVING|\n",
      "+------------+--------------+\n",
      "|           1|            19|\n",
      "|           2|            25|\n",
      "|           3|            12|\n",
      "|           4|            43|\n",
      "|           5|            27|\n",
      "|           6|            23|\n",
      "|           6|            12|\n",
      "|           8|            28|\n",
      "|           9|            17|\n",
      "|          10|             1|\n",
      "|          11|            48|\n",
      "|          12|            46|\n",
      "|          13|            30|\n",
      "|          14|             4|\n",
      "|          15|             3|\n",
      "|          16|            11|\n",
      "|          17|            35|\n",
      "|          17|            20|\n",
      "|          19|            32|\n",
      "|          20|            29|\n",
      "+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_iteration.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OVERALL RANK: integer (nullable = true)\n",
      " |-- COST OF LIVING: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vector_assembler = VectorAssembler(inputCols = ['COST OF LIVING'], outputCol = 'features')\n",
    "vector_output = vector_assembler.transform(df_iteration)\n",
    "vector_output.printSchema()\n",
    "vector_output.head(1)\n",
    "label_features = vector_output.select(\"features\", \"OVERALL RANK\").toDF('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.1901319441911117]\n",
      "Intercept: 20.57064861754576\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr1 = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lrModel1 = lr.fit(label_features)\n",
    "print(\"Coefficients: %s\" % str(lrModel1.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel1.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
